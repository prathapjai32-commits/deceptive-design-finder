"""
Screenshot Capture Module for Dark Pattern Detection
Captures visual evidence of dark patterns (fake reviews, items, etc.)
"""

import requests
from bs4 import BeautifulSoup
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
import re
from urllib.parse import urljoin, urlparse

class PatternScreenshotCapture:
    """Capture screenshots and highlight dark pattern elements"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def create_synthetic_screenshot(self, element_type, content_data, website_url):
        """Create synthetic screenshot highlighting detected patterns"""
        # Create a professional-looking screenshot mockup
        width, height = 1200, 800
        img = Image.new('RGB', (width, height), color='white')
        draw = ImageDraw.Draw(img)
        
        # Draw header
        header_color = (102, 126, 234)  # #667eea
        draw.rectangle([0, 0, width, 100], fill=header_color)
        
        # Draw content area
        draw.rectangle([50, 120, width-50, height-50], outline=(200, 200, 200), width=2)
        
        # Title
        try:
            font_title = ImageFont.truetype("arial.ttf", 32)
            font_subtitle = ImageFont.truetype("arial.ttf", 20)
            font_text = ImageFont.truetype("arial.ttf", 16)
        except:
            font_title = ImageFont.load_default()
            font_subtitle = ImageFont.load_default()
            font_text = ImageFont.load_default()
        
        draw.text((width//2 - 200, 25), "Dark Pattern Detection", fill='white', font=font_title)
        
        # Website info
        draw.text((60, 140), f"Website: {website_url}", fill=(100, 100, 100), font=font_subtitle)
        
        # Pattern type
        y_offset = 180
        
        if element_type == 'fake_reviews':
            draw.text((60, y_offset), "⚠️ FAKE REVIEWS DETECTED", fill=(245, 87, 108), font=font_subtitle)
            y_offset += 40
            
            # Display review samples
            if isinstance(content_data, list):
                for i, review in enumerate(content_data[:5]):
                    review_text = review.get('text', review) if isinstance(review, dict) else str(review)
                    review_text = review_text[:80] + '...' if len(review_text) > 80 else review_text
                    
                    # Highlight suspicious review
                    draw.rectangle([70, y_offset-5, width-70, y_offset+30], 
                                 outline=(245, 87, 108), width=2, fill=(255, 240, 240))
                    draw.text((80, y_offset), f"Review {i+1}: {review_text}", 
                            fill=(50, 50, 50), font=font_text)
                    y_offset += 45
        
        elif element_type == 'sneak_into_basket':
            draw.text((60, y_offset), "⚠️ AUTO-ADDED ITEMS DETECTED", fill=(245, 87, 108), font=font_subtitle)
            y_offset += 40
            
            if isinstance(content_data, list):
                for i, item in enumerate(content_data[:5]):
                    item_text = item.get('name', item) if isinstance(item, dict) else str(item)
                    item_text = item_text[:60] + '...' if len(item_text) > 60 else item_text
                    
                    draw.rectangle([70, y_offset-5, width-70, y_offset+30],
                                 outline=(255, 167, 38), width=2, fill=(255, 250, 240))
                    draw.text((80, y_offset), f"✓ {item_text}", 
                            fill=(50, 50, 50), font=font_text)
                    y_offset += 40
        
        elif element_type == 'confirm_shaming':
            draw.text((60, y_offset), "⚠️ CONFIRM SHAMING DETECTED", fill=(245, 87, 108), font=font_subtitle)
            y_offset += 40
            
            if isinstance(content_data, list):
                for i, text in enumerate(content_data[:3]):
                    draw.rectangle([70, y_offset-5, width-70, y_offset+30],
                                 outline=(245, 87, 108), width=2, fill=(255, 240, 240))
                    draw.text((80, y_offset), f'Button: "{text}"', 
                            fill=(50, 50, 50), font=font_text)
                    y_offset += 45
        
        # Footer
        draw.rectangle([0, height-40, width, height], fill=(240, 240, 240))
        draw.text((width//2 - 150, height-30), 
                 "Generated by Dark Pattern Detector", 
                 fill=(100, 100, 100), font=font_text)
        
        # Convert to base64
        buffered = BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return img_str
    
    def extract_review_elements(self, soup, html_content):
        """Extract review elements from HTML"""
        reviews = []
        
        # Common review patterns
        review_selectors = [
            {'class': re.compile(r'review', re.I)},
            {'class': re.compile(r'rating', re.I)},
            {'class': re.compile(r'comment', re.I)},
            {'itemprop': 'review'},
            {'class': re.compile(r'testimonial', re.I)}
        ]
        
        for selector in review_selectors:
            elements = soup.find_all(['div', 'span', 'p'], selector)
            for elem in elements[:10]:  # Limit to first 10
                text = elem.get_text(strip=True)
                if len(text) > 20:  # Meaningful review
                    reviews.append({
                        'text': text[:200],
                        'element': str(elem)[:500]
                    })
        
        return reviews[:10]
    
    def extract_item_elements(self, soup, html_content):
        """Extract auto-added items from HTML"""
        items = []
        
        # Common item/cart patterns
        item_selectors = [
            {'class': re.compile(r'add.*cart', re.I)},
            {'class': re.compile(r'selected', re.I)},
            {'class': re.compile(r'checkbox.*checked', re.I)},
            {'data-selected': 'true'},
            {'checked': True}
        ]
        
        for selector in item_selectors:
            elements = soup.find_all(['div', 'input', 'label', 'span'], selector)
            for elem in elements[:10]:
                text = elem.get_text(strip=True) or elem.get('value', '') or elem.get('name', '')
                if text:
                    items.append({
                        'name': text[:100],
                        'element': str(elem)[:300]
                    })
        
        return items[:10]
    
    def extract_shaming_elements(self, soup, html_content):
        """Extract confirm shaming buttons/text"""
        shaming_texts = []
        
        shaming_patterns = [
            r'no thanks',
            r'not interested',
            r'maybe later',
            r'skip',
            r'decline',
            r'i don\'t want',
            r'pass'
        ]
        
        # Find buttons with shaming text
        buttons = soup.find_all(['button', 'a', 'span'], 
                               string=re.compile('|'.join(shaming_patterns), re.I))
        
        for btn in buttons[:10]:
            text = btn.get_text(strip=True)
            if text:
                shaming_texts.append(text)
        
        return shaming_texts[:10]
    
    def capture_pattern_evidence(self, html_content, soup, website_url, pattern_type):
        """Capture visual evidence of specific dark patterns"""
        evidence = {
            'screenshots': [],
            'elements': []
        }
        
        if pattern_type == 'fake_reviews':
            reviews = self.extract_review_elements(soup, html_content)
            if reviews:
                screenshot = self.create_synthetic_screenshot('fake_reviews', reviews, website_url)
                evidence['screenshots'].append({
                    'type': 'fake_reviews',
                    'base64': screenshot,
                    'elements': reviews
                })
        
        elif pattern_type == 'sneak_into_basket':
            items = self.extract_item_elements(soup, html_content)
            if items:
                screenshot = self.create_synthetic_screenshot('sneak_into_basket', items, website_url)
                evidence['screenshots'].append({
                    'type': 'sneak_into_basket',
                    'base64': screenshot,
                    'elements': items
                })
        
        elif pattern_type == 'confirm_shaming':
            shaming = self.extract_shaming_elements(soup, html_content)
            if shaming:
                screenshot = self.create_synthetic_screenshot('confirm_shaming', shaming, website_url)
                evidence['screenshots'].append({
                    'type': 'confirm_shaming',
                    'base64': screenshot,
                    'elements': shaming
                })
        
        return evidence
